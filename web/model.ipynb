{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec #@\n",
    "from gensim.utils import simple_preprocess #@\n",
    "from gensim.models.keyedvectors import KeyedVectors #@\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model #모델 저장\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import time #수행시간 측정\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 셋팅 =============== #\n",
    "\n",
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "#전처리\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1600000, 6)\n"
     ]
    }
   ],
   "source": [
    "#학습데이터 로드\n",
    "dataset=pd.read_csv('./train.csv',encoding = DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "print(dataset.shape) #1600000,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>ids</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset.head() # negative:0, positive:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 텍스트 전처리\n",
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.text = dataset.text.apply(lambda x: preprocess(x)) #전처리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN size: 1280000\nTEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(train))\n",
    "print(\"TEST size:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 400000\n",
    "tk = Tokenizer(num_words=vocab_size)\n",
    "tk.fit_on_texts(train.text)\n",
    "max_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./text-CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ex_text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    x_encoded = tk.texts_to_sequences([ex_text])\n",
    "    res_test=np.array(pad_sequences(x_encoded, maxlen=max_len, padding='post'))\n",
    "    # Predict\n",
    "    score = model.predict([res_test])\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "    \n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"I love it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({'text':[],\n",
    "                   'label':[],\n",
    "                   'score':[],\n",
    "                  'elapsed_time':[]}) #결과 dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRes(samples):\n",
    "  for col,item in samples.iterrows():\n",
    "    res=predict(item[0])\n",
    "    df_res.loc[col]=[ item[0], res['label'], res['score'],res['elapsed_time'] ]\n",
    "  return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, render_template, request\n",
    "from werkzeug.utils import secure_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x2958788fcc8>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#업로드 html 렌더링\n",
    "@app.route('/')\n",
    "def render_file():\n",
    "    return render_template('file.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sample):\n",
    "    list_text=[]\n",
    "    list_label=[]\n",
    "    list_score=[]\n",
    "\n",
    "    for col,item in sample.iterrows():\n",
    "        res=predict(item[0])\n",
    "        list_text.append(item[0])\n",
    "        list_label.append(res['label'])\n",
    "        list_score.append(res['score'])\n",
    "\n",
    "    dic = {'text':list_text,'label':list_label,'score':list_score}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 업로드 처리 + node 서버로 전달\n",
    "@app.route('/fileUploaded',methods=['POST'])\n",
    "def upload_file():\n",
    "    if request.method=='POST':\n",
    "        f = request.files['file']\n",
    "        print(f)\n",
    "        f.save(secure_filename(f.filename))\n",
    "        print(\"TEST\")\n",
    "        sample=pd.read_csv(f.filename, sep = \"\\n\",encoding = \"utf8\",header=None)\n",
    "        predict = predict_sentiment(sample)\n",
    "    return predict_sentiment(sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/info')\n",
    "def dataInfo2():\n",
    "    data = {\"name\":\"test\",\"account\":\"@realDonald\"}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def toJson(df):\n",
    "    tmp = df.to_json(orient='records')\n",
    "    parsed = json.loads(tmp)\n",
    "    res = json.dumps(parsed['data'])  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json={} #사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=pd.read_csv('sample.txt',sep = \"\\n\",encoding = \"utf8\",header=None)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = ['a','bc']\n",
    "dic = {'key':a,'b':b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_res.to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = json.loads(res)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=json.dumps(parsed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [03/Nov/2020 16:19:37] \"\u001b[37mGET /info HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Nov/2020 16:19:38] \"\u001b[37mGET /info HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Nov/2020 16:19:38] \"\u001b[37mGET /info HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Nov/2020 16:20:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Nov/2020 16:31:34] \"\u001b[37mGET /info HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Nov/2020 16:31:53] \"\u001b[37mGET /info HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.config['JSON_AS_ASCII'] = False\n",
    "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\n",
    "if __name__ ==\"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}